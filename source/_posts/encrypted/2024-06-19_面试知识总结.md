---
title: 面试知识总结
tags:
categories:
hidden: true
abbrlink: 2211132a
math: true
description: 面试常见问题要点汇总
date: 2024-06-19 22:44:50
---

# Redis

## 数据类型

* **String**: sds
* **List**:
  - 3.2前:
    - 元素数量少于512，每个元素小于64字节，使用ziplist
    - 否则使用双向链表
  - 3.2后:
    - 使用quicklist
    - 双向链表的节点是ziplist
* **Set**：
  * 元素个数小于512，且都是整数，用整数集合
  * 否则用hashmap
* **ZSet**：
  * 元素个数小于128，且每个元素小于64字节，用ziplist
  * 否则用skiplist
* **Hash**：
  * 元素个数小于512，且每个值小于64字节，使用ziplist
  * 否则用hashmap
  * 7.0开始废弃ziplist，改用listpack
* **BitMap**：
* **HyperLogLog**：
* **Geo**：
* **Stream**：

## 数据结构

* **list**:
  * 缺陷：无法利用cpu缓存
* **ziplist**:
  * 缺陷：连锁更新
* **hash**:
  * 链式哈希解决冲突
  * 双hash、动态扩容
* **Skiplist**:
  * 创建节点时，生成0-1的随机数，如果小于0.25，+1层，继续生成，直到层数达到层高限制或者大于0.25
  * 比平衡树**实现简单，更紧凑，占用空间小，支持范围遍历**
* **quicklist**:
* **listpack**:
  * 解决了ziplist连锁更新问题

## 持久化

### AOF：记录写操作命令
  * **写回策略**：
    * always：所有命令立即fsync到磁盘
      * 数据丢失最少，性能最差
    * everysec：每秒fsync到磁盘
    * no：由系统控制写回时机
      * 数据丢失最多，性能好
  * **重写机制**：
    * **后台重写**：
      * 数据大时，fork复制页表会阻塞主进程
      * Cow时会阻塞主进程
### RDB：内存快照
  * 执行save或bgsave
  * Bgsave会创建子进程

## 过期策略：

* **定期 + 惰性**
  * 定期频率：默认10 HZ，随机抽取20个key，如果过期率超过25%，则继续抽取，最长25ms

## 淘汰策略：

> **3.0默认不淘汰**，内存超过阈值后，不接受新key写入，只能读
> LRU： 随机抽5个key，淘汰最久未使用的
> LFU： 24bit分为 16bit时间戳 + 8bit 使用频率

* **过期key里淘汰**
  
  * random
  * ttl： 淘汰最早过期
  * lru
  * lfu

* **所有数据里淘汰**
  
  * random
  * lru
  * lfu

## 高可用

* **主从**： 读写分离
  
  * 数据同步：
    * 从节点第一次同步全量同步：
      1. 主进程fork子进程，执行bgsave生成RDB，传输RDB且从节点，从节点收到RDB后清空数据，载入RDB
      2. 从节点同步数据期间，主节点记录所有更新命令到 replication buffer
      3. 主节点收到从节点确认消息后，发送 replication buffer中的命令给从节点
    * 第一次同步完成后，主从之间保持长链接，进行后续命令同步：
      * 主节点维护repl_backlog_buffer和replication offset：
        * repl_backlog_buffer: 环形缓冲区
        * replication offset表示当前同步进度：
          * master_repl_offset：主节点写进度
          * slave_repl_offset：从节点读进度
      * 如果主从同步出现断连，重连后：
        * 如果从节点为同步命令还在repl_backlog_buffer,采用增量同步
        * 否则重新开始全量同步
  * 过期key处理：主节点模拟del命令发给从节点
  * 主从切换数据丢失：
    * **异步复制**：同步给从节点前，主节点下线，导致数据丢失
    * **脑裂**：主节点和client网络正常，但是和从节点网络异常，导致哨兵选举新的主节点
      * min-slaves-to-write x：至少x个从节点连接，少于x主节点拒绝写入
      * min-slaves-max-lag x：主从同步延迟应低于x秒，否则拒绝写入

* **哨兵**：
  
  * 判断主节点故障： 
    * 主观下线：每秒心跳检测，如果没有在规定时间返回，标记为主观下线
    * 客观下线：询问其他哨兵对主关下线的机器投票，如果确认下线的票数超过quorum（一般哨兵数的一半+1），标记为客观下线，开始执行故障转移
  
  * 选举故障转移执行人：识别出主节点客观下线的哨兵作为候补leader，与其他哨兵互相投票，每个哨兵只有一票，候补哨兵投给自己，赞成票达到quorum的作为leader执行故障转移
  
  * 故障转移：
    * 根据从节点优先级、复制进度、id排序，选取新主节点
    * 哨兵发送slaveof命令给其他从节点修改主节点
    * 哨兵通过发布订阅模式通知新主节点ip给client

## 数据一致性

* **旁路缓存**：更新时删除缓存，读取时写入缓存

* **雪崩**：大量key同时过期
  
  * 均匀过期时间，随机数
  * 互斥锁，保证同时只有一个请求查询数据库，singleflight
  * 后台更新
    * 缓存不过期，后台异步定期更新缓存
      * 有数据淘汰风险，
      * 更新有延迟
    * 消息队列：
      * 有延迟
  * 熔断：直接返回错误，有业务损失
  * 限流：只放过部分请求，业务损失可接受
  * 主从、cluster

* **击穿**：热点key过期
  
  * 互斥锁
  
  * 异步更新

* **穿透**：大量请求查询不存在的key
  
  * 请求校验， 过滤明显异常请求
  
  * 构造空key
  
  * 布隆过滤器

## 应用

* 点赞： set

* 网站uv： hyperloglog

* 共同关注： set

* 排行榜： zset

* 购物车： hash

* 队列： stream

* 分布式锁： string

* 全局唯一id生成： string

* 抽奖： set

* 签到： bitmap

* 布隆过滤器： bitmap

# 系统

## 进程调度算法

* **FIFO**: 先来先服务

* **最短任务优先**：短任务多时会导致长任务饥饿

* **高响应比**：理想算法，没法实用 （等待时间+预计执行时间）/预计执行时间

* **高优先级优先**：会导致低优先级任务饥饿

* **时间片轮转**：长任务会被频繁打断， 频率越高，效率越差，频率越低，资源浪费越严重

* **多级反馈队列**：设定多个不同时间片队列，初始任务都在最短时间片队列，如果没执行完移到下一级队列，且每一级队列等候时间不同，时间片越长，等候时间越长，且如果短队列有任务，可以打断长任务执行

## 内存页面置换

* **FIFO**：先进先出

* **LRU**：有缓存污染和预读失效问题，且管理列表资源损耗大， linux采用两级队列解决，初始放入old队列队头，真正使用时放入young队列队头，并把young队列最久没使用的页放入old队列队头

* **LFU**：维护频次成本高，查找效率低，刚开始频繁访问但次数不高的页面会被误伤

## 锁

* **悲观锁**：适用多线程同时修改资源概率高的场景

* **互斥锁**：加锁失败需要两次线程上下文切换（线程睡眠换出，睡眠中的线程换入）

* **自旋锁**：忙等，适合执行时间短

* **读写锁**：适用能明确区分读写的场景， 分读优先和写优先、公平（fifo）

* **乐观锁**：基于CAS，适用多线程同时修改资源概率低的场景

### 死锁：

* 四个条件： **互斥、持有等待、不可剥夺、循环依赖**

## 进程通信方式

* **管道**：匿名管道、具名管道，单向通信， 系统调用：pipe，匿名管道只能父子进程通信，命名管道可以不相关进程通信

* **共享内存**：把一块虚拟地址映射到同一块物理地址

* **消息队列**：通信不及时，附件有大小限制，存在用户态和内核态数据拷贝

* **信号量**：可携带数据更少，支持P（-） V(+)操作，主要用于进程同步

* **信号**： kill -9 

* **socket**： 

## IO类型

* **BIO**： 同步阻塞，一直等待，直到数据可读

* **NIO**： 同步非阻塞，数据不可读时直接返回错误，循环尝试，直到数据可读

* **多路复用**： 仍属于同步io
  
  * **Select**： 需要频繁在用户态和内核态做数据拷贝，数组形式维护，有长度限制，需要遍历数组发现可读状态
  * **Poll**： 链表形式维护，没有长度限制，但依然需要遍历及用户态内核态拷贝
  * **Epoll**： 内核用红黑树维护文件描述符，只需要拷贝给定的文件描述符，基于事件机制， 分为
  * **水平触发**：只要还有数据可读，就触发
  * **边缘触发**：只触发一次
  * Reactor：基于多路复用，redis是多reactor，单线程模型，

* **AIO**：异步IO，应用把需要读取的文件描述符和读取到的目标位置给内核，由内核读取完成后，通知应用

## 零拷贝

* mmap + write： 磁盘->内核缓冲区 -> mmap到用户空间 -> 用户write到sokect缓冲区->网卡

* linux 2.1 提供sendfile系统调用： 磁盘->内核缓冲区 -> sokect缓冲区 -> 网卡

* Linux 2.4 利用sg-dma 完成内核缓冲区->网卡的copy，不需要cpu参与

# MySQL

## 事务

### 特性：
  
  * **原子性**： 要么都成功，要么都不成功， 通过undolog保证
  * **一致性**： 事务前后数据满足完整性约束，
  * **持久性**： 事务结束后，数据变化是永久有效的，通过redolog实现
  * **隔离性**： 事务之间不能互相影响，通过mvcc + 锁保证

### 隔离级别：
  
  * **读未提交**：有脏读问题
  * **读已提交**： 不可重复读，有幻读问题
  * **可重复读**： 默认隔离级别，有幻读问题，但通过mvcc+间隙锁，一定程度上解决了幻读
  * **串行化**： 性能差，一般不用
  
  > * **脏读**： 事务读取到别的未完成事务修改的数据
  > * **不可重复度**： 前后两次读取数据不一致
  > * **幻读**： 读取到其他事务删除或添加的数据

### MVCC:
  
  * ReadView:
    * creator_trx_id：创建ReadView的事务id 
    * m_ids：创建Readview时活跃未提交事务id列表
    * min_trx_Id：创建ReadView时活跃事务中最小的事务id
    * max_trx_id：创建ReadView时应该分配的下一事务id
  * 聚簇索引记录中的隐藏列：
    * trx_id：最后修改的事务id
    * roll_pointer： undolog链表
  * 事务访问记录分三种情况：
    1. 聚簇索引trx_id小于min_trx_id：说明在当前事务之前创建，可见
    2. 聚簇索引trx_id 大于等于min_trx_id，小于max_trx_id：
       * 在m_ids里：生成该记录的事务未完成，不可见
       * 不在m_ids里：生成该记录的事务已完成，可见
    3. 聚簇索引trx_id >= max_trx_id：在当前事务之后创建，不可见
       * 读提交和可重复度差异：
  * 读已提交： ReadView在每次读时新建
  * 可重复度：在事务开始时创建ReadView

## 锁

* **全局锁**
  
  ```sql
  flush tables with read lock
  unlock tables
  ```
  
  * 用于全库逻辑备份
  
  * 所有修改操作被阻塞

* **表级锁**
  
  * 表锁：与行锁冲突
    
    * ```sql
      lock tables _table read;
      lock tables _table write;
      ```
  
  * 元数据锁：
    
    * 修改表结构自动加写锁
    
    * 防止CRUD时表结构变更
    
    * CRUD自动加读锁
  
  * 意向锁：
    
    * 意向锁之间不冲突
    
    * 与表锁冲突，用于避免加表锁时遍历所有记录
    
    * 与行锁兼容

* **行锁**
  
  > 加锁对象是**索引项**
  
  * **记录锁**：
  
  * **间隙锁**：用于防止一个事务没完成，别的事务在间隙插入/删除数据
    
    * 间隙锁之间兼容，多个事务可以获取同一间隙范围的锁
  
  * **Next-Key**：记录锁+间隙锁，左开右闭
    
    * 如果右侧记录不存在，退化成间隙锁
    
    * 需考虑记录锁间的冲突
  
  * **插入意向锁**：属于记录锁，多事务相斥，与间隙锁相斥
    
    * 事务插入记录时，需要判断是否有间隙锁，有的话生成插入意向锁

## 存储

### 行结构

- Compact: 5.1后默认行格式
  
  | 变长字段列表 | NULL值列表 | 记录头 | row_id | trx_id | roll_ptr | 列1 | 列2 | 列3 |
  | ------------ | ---------- | ------ | ------ | ------ | -------- | --- | --- | --- |

- Dynamic：5.7后默认

### 单表数量限制计算

* 索引行：长度12字节
  
  * 页中最小记录id + 页号地址

* 单页总共16k，15k可用

* 3层b+tree,单记录1k算，能容纳
  
  * $(\frac{15*1024}{12})^2 * 15 = 1280^2 * 15 = 24576000$

## 索引

### 分类
  
  - **按数据结构**
    
    - B+Tree
    
    - Hash
    
    - Full-text
  
  - **按物理存储**
    
    - 聚簇索引
    
    - 非聚簇索引
  
  - **按字段特性**
    
    - 主建索引
    
    - 唯一索引
    
    - 普通索引
    
    - 前缀索引
  
  - **按字段个数**
    
    - 单列索引
    
    - 联合索引

### 索引失效
  
  * 对索引使用函数、表达式计算
  
  * 对索引隐式类型转换，入 str -> int
  
  * 联合索引非最左匹配

## 分库分表

- **垂直分表**：一般按业务拆分

- **水平分表**：需要考虑全局唯一key
  
  - 雪花算法：趋势递增，强依赖机器时钟
  
  - 叶子算法：
    
    - Leaf-segment: proxy批量获取号段，减少访问数据库次数
    
    - Leaf-snowflake：基于雪花算法
  
  - uuid：不易存储，占用空间大，不利于索引
  
  - 自增：需要发号服务
    
    - 固定步长+不同起始偏移：水平扩展困难
    
    - 号段：

# 网络

## Tcp/IP模型

### 1. 应用层

#### HTTP

##### HTTP 1.1

- 长链接、管道：有队头堵塞问题，服务端必须按照请求顺序返回

- 缺陷：
  
  - 请求/响应头没压缩，资源浪费
  
  - 只能client发起请求
  
  - 队头阻塞

##### HTTP 2

- 基于https，安全

- header压缩

- 二进制传输
  
  - header frame
  
  - data frame

- Stream：每个请求分配streamid，可时分复用连接，双向

- 基于tcp实现，由于tcp的顺序性，也有队头堵塞问题

##### HTTP 3

- 基于UDP
  
  - 用QUIC协议保证可靠性

#### HTTPS

1. client发起请求，生成随机数 random1，以及支持的算法，ssl版本

2. server收到请求后，校验ssl版本， 生成随机数random2，用自己的私钥加密，和证书一起发给client

3. client收到响应后，校验证书有效性，如果有效，则从证书里取出服务端公钥，生成随机数random3，用公钥加密，传给server

4. 此时client和服务端都有了random2，random3，可以生成同样的对称加密私钥，后续通信都用私钥加密；服务端需要返回确认通知，包含之前信息的摘要，供client校验

##### 建立连接过程

### 2. 传输层

#### TCP

##### 三次握手

- server没调用listen时，client调用connect会收到server返回的RST包

- 对端没有调用listen也可以建立连接，要求
  
  - 对端同时通过connect连接当前机器
  
  - 或者client connect自己

##### 四次挥手

- MSL在linux里固定为30秒

- Timewait状态优化
  
  1. tcp_max_tw_buckets表示最多可以有多少个连接处于Timewait状态，超过时直接关闭连接
  
  2. tcp_tw_reuse表示建立连接时（调用connect()）可以重用Timewait状态的连接，只能用于client
     
     - 跳过Timewait状态，可能收到历史RST包，由于RST包优于时间戳校验，会导致连接直接断开
     
     - 跳过Timewait状态，可能导致被动连接方在没收到第四次ack包而重传fin包后，收到client的RST包，从而异常退出

##### 重传机制

###### 超时重传

* 定时器，超时未收到ack，开始重传

* 超时时间RTO要比RTT略大

###### 快速重传

- 收到3个相同ack，可确认包丢失，立即重传

- 无法确认重传一个包，还是重传所有包

- ###### **SACK**
  
  - 在TCP选项里添加已接收包的信息

##### 流量控制

- ###### 滑动窗口
  
  | 已确认数据 | 已发送未ack | 待发送对方可接收 | 未发送超出对方接收窗口 |
  | ---------- | ----------- | ---------------- | ---------------------- |
  
  | 已接收并ack | 未接收但可以接收（接收窗口） | 不能接收 |
  | ----------- | ---------------------------- | -------- |
  
  窗口减少到0时，开启定时器，开始发送窗口探测报文
  
  - 一般探测3次，大约30-60秒每次，如果3次后窗口还是0，有可能发送RST断开链接

##### 拥塞控制

> cwnd：拥塞窗口，ssthresh：拥塞避免门限

###### 慢启动

- 每收到一个ack，拥塞窗口cwnd+1（等于每次翻倍）

###### 拥塞避免

- cwnd涨到ssthresh后，开始线性增长
  
  - 每收到一个ack，$cwnd += \frac{1}{cwnd}$

- 一般ssthresh=65535

###### 拥塞发生

- 发生超时重传后
  
  - ssthresh设为cwnd/2
  
  - cwnd设为1，重新开始慢启动

- 发生快速重传后
  
  1. ssthresh = cwnd / 2
  
  2. 开始快速恢复

###### 快速恢复

1. cwnd = ssthresh + 3
   
   - 此时ssthresh = 拥塞发生时cwnd的一半
   - 3 表示快速重传收到的3个重复ack

2. 每收到一个重复ack，cwnd+1
   
   - 主要为了快速把丢失的包发给目标

3. 直到收到新的ack，恢复过程结束，把cwnd设置为ssthresh，重新开始拥塞避免

##### 半连接、全连接队列

- **半连接队列（SYN队列）**：
  
  - server收到client的connect syn包后，把连接放到半连接队列里
  
  - 通过增大somaxconn和backlog可以增大半连接队列

- **全连接队列**
  
  - server收到client的ACK包后，把连接放入全连接队列
  
  - accept()从全连接队列中取出连接，读取数据
  
  - **全连接队列满了以后，默认会丢弃连接，可以把tcp_abort_on_overflow设置为1，系统会给client发送rst包，直接断开连接，不过一般不建议，因为即使连接被丢弃了，client已经进入Establish状态，会不停重发包，如果server全连接队列有空位了，可以直接进入Establish**

- SYN包何时被丢弃
  
  - 半连接队列满了
  
  - 老的linux有tcp_tw_recycle参数，表示快速回收Timewait的连接，但是开启后，会有PAWS机制，已IP为单位，校验tcp option里的时间戳，直接丢弃过时的包，如果server处于NAT网络，所有client的连接到达后都是同一个IP，如果A断开连接后，收到B的SYN，且B的时钟是过去，就会直接丢弃B的SYN包

- 开启syncookies可以在半连接队列满了以后，成功建立连接

# kafka

## 消息丢失

- 生产端：
  
  - 异步发送消息，broker每收到或者broker保存前down
  
  - leader broker 宕机，选举出的新leader落后太多

- 消费端：
  
  - 手动commit，先commit后处理，如果commit后立即down了，会丢消息
  
  - 自动commit
    
    - 消息处理慢，处理完前commit了，但是处理失败了
    
    - 在commit前由于消费处理太慢等原因导致rebalance

## 重复消费

- 手动commit时，先处理后commit，如果commit前down了，重启后会重复消费

- 自动commit时，如果在commit前down了，重启后会重复消费

## 分区leader选举策略

- OfflinePartition：每当有新Partition上线，就执行选举

- ReassignPartition：手动运行kafka-reassign-partitions命令，或者调用Admin的alterPartitionReassignments方法来执行分区副本重分配，可能触发选举

- PreferredPartition：手动运行kafka-preferred-replica-election 命令，或自动触发了 Preferred Leader 选举时

- ControlledShutdownPartition：当Broker正常关闭时，该Broker上的所有Leader都得下线，因此需要执行重新选举

## ACK机制

1. 0: 生产者不等待broker ack

2. 1：生产者等待leader broker ack

3. -1：生产者等待所有broker ack

# GO
